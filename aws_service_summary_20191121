1. VPC , Virtual Private Cloud 
> 기능
- private IP address 를 제공하여, 독립된 클라우드 공간을 제공한다. 
- secondary IP ranger를 추가하여 확장가능하다. 
- 하나 이상의 public/private subnet을 통하여 VPC의 private IP 주소 공간을 나누어준다. 
- network access control list를 통해 각 네트워크에 대해서 inbound/outbound 접근을 제공한다. 
- S3에 데이터를 저장하고 VPC 내부의 데이터 접근 권한 등을 관리한다. 
- 하나 이상의 EIP 주소를 부여하여 인터넷을 통해 직접적으로 접근이 가능하도록 한다. 
- VPC peering을 통해서 private IP 주소로 VPC간 리소스 접근이 가능하도록 한다. 
- IGW, NAT, FW-proxy를 통한 VPC Endpoint 없이 AWS 서비스에 접근할 수 있다.  (S3, DynamoDB, Kinesis Stream, Service Catalog, EC2 System Manager, ELB API, EC2 API, SNS 등) 
- AWS PrivateLink를 통해서 개인적인 연결을 하여 자체 서비스나 SaaS에 접근 가능하다. 
- AWS Site-to-Site VPN을 통해 자체 구성한 IT 인프라(온프렘)과 VPC를 연결할 수 있다. 
- Classic EC2 인스턴스 플랫폼을 private IP 주소를 통해 VPC 의 인스턴스와 통신할 수 있다. 
- VPC security Group을 EC2-Classic 인스턴스와 연계할 수 있다. 
- VPC flow log를 통해서 VPC에 들어오고 나가는 정보를 확인할 수 있다. 
- IPv4, IPv6를 동시에 사용할 수 있다. 
- VPC traffic mirroring을 통해서 EC2에 대한 네트워크 트래픽을 확인하거나 미러링 할 수 있다. 

> PrivateLink 
- Public IP들의 사용없이 VPC 내부에서 수행되는 서비스들에 대한 접근을 하기 위한 기능 
- 서비스 endpint를 생성 하면 PrivateLink를 사용할 수 있는데 이것의 endpoint가 ENI(Elastic Network Interface)들에 VPC에 대한 IP들이 보이게 된다. IGW,VPN,NAT,Firewall-proxy나 publicIP에 대한 whiltelist없이 접근할 수 있다. 
- 서비스들은 AWS Direct connect를 기반으로 한 PrivateLink를 통해서 접근하거나, AWS VPN을 통해서 온프렘 어플리케이션들이 VPC 내부로 접근할 수 있다. 
- PrivateLink에서 현재 EC2 API, ELB API, Kinesis Stream, EC2 System Maanger, Service Catalog, SNS 들이 사용가능하다. 
	
>질문 
- VPC란 무엇인가? 
. 논리적으로 AWS 클라우드 내에서 고립된 클라우드를 제공하여 AWS 리소스가 VPC위에서 수행될 수 있게 한다. 이것은 개인적인 가상 네트워크에서 IP 주소범위 선택, 서브넷 생성, 라우팅 테이블 과 네트워크 게이트웨이 같은 네트워크 환경을 완벽하게 제어할 수 있게 해준다. 이와 더불어 물리적인 VPN 연결을 기업의 데이터 센터와 VPC 간에 연결하여 데이터센터에 대해 AWS로의 확장성을 제공한다. 퍼블릭 서브넷과 프라이빗 서브넷 구성을 통해서 인터넷 접근이 필요한 레이어와 그렇지 않은 레이어를 나누고, 여러 레이어의 보안 그룹, network access control list를 설정함으로써 각 서브넷 안에 있는 인스턴스에 대한 접근 제어를 할 수 있다. 

- VPC의 컴포넌트는 무엇이 있는가? 
	. VPC : AWS 클라우드에서 논리적으로 고립된 가상 네트워크 
	. Subnet : VPC 주소 범위에 대한 부분으로, 서브넷을 통해 독립적으로 리소스 그룹들 위치시킬 수 있다. 
	. Internet Gateway  : VPC 에서 public 인터넷에 접근하기 위한 게이트웨이 
	. NAT Gateway : 고가용성을 보장하는 관리형 Network Address Translation 서비스로 private subnet에 있는 리소스에 대해서 인터넷 접근을 가능토록 한다. 
	. Virtual private gateway : VPC 내부의 VPN 연결을 위한 gateway 
	. Peering Connection : private IP 주소로 페어링 된 VPC들간의 트래픽 라우팅을 가능하게 하는 연결  
	. VPC Endpoint : IGW, VPN, FWproxy, NAT접근 없이 VPC 내부의 리소스에서 AWS 에 있는 서비스들에 대한 private 연결 가능하게 함. 
	. Egress-only Internet Gateway : IPv6에 대해서 VPC 에서 인터넷으로만 나갈수 있는 stateful gateway를 제공 
- 언제 VPC를 사용해야 하는가? 
. VPC는 AWS 내부에서 가상내트워크를 구성할 수 있도록 한다. VPN이나 물리전 데이터센터 요구사항 없이. 그 안에서 자신만의 네트워크 구성과 설정을 가능하고 어떻게 EC2 인스턴스들이 네트워크에 노출될 것인지에 대한 제어를 할 수 있다. 또한 보안 옵션들을 VPN 에서 제공함으로써 각 리소스에 대해 더 세밀한 접근 제어를 제공한다. 

- 어떻게 VPC를 시작해야 하는가? 
. AWS 리소스들은 자동으로 default VPC에 프로비전 되는데, 추가적인 VPC 생성을 AWS 매니지먼트 콘솔을 이용해서 할 수 있다. 네트워크 설정을 위한 기본적인 4가지 옵션을 선택한다.
1) Amazon VPC with a single public subnet only
2) Amazon VPC with public and private subnets
3) Amazon VPC with public and private subnets and AWS Site-to-Site VPN access
4) Amazon VPC with a private subnet only and AWS Site-to-Site VPN access

- VPC에서 사용가능한 VPC endpoint의 종류는 무엇이며, 차이는 무엇인가? 
. VPC 엔드포인트는 IGW, NAT, VPN, firewall proxies 를 사용하지 않고 VPC 안의 서비스에 접근할 수 있도록 한다. Endpoint는 수평적으로 스케일아웃할 수 있는 고가용성 가상 장비이다. 이것은 VPC 인스턴스와 AWS 서비스 간의 통신을 허용한다. VPC 는 두가지 다른 타입의 endpoint를 제공한다. 
1) Gateway type endpoint : 오직 AWS 서비스들(S3, DynamoDB 등)에 대해서만 사용가능하다. 이러한 엔드포인트는 route table에 추가할 수 있고, 아마존 private 네트워크를 통해서 서비스로 트래픽을 라우팅할 수 있다. 
2) Interface type endpoint  : PrivateLink를 통한 private 연결로 사용자 자체적인 서비스나 Saas 솔루션들을 Direct Connect를 통한 연결을 하고자 할때 사용한다. 


2. ELB, Elastic Load Balancing 
> 개요 : 들어오는 application 트래픽을 EC2, Container, 특정 IP주소, Lambda 함수와 같은 여러 대상에 자동으로 분산시킴. 
ELB는 단일 AZ, 여러 AZ에서 다양한 application 트래픽을 처리할 수 있습니다. ELB 에서 제공하는 ALB, NLB, CLB 모두 고가용성, 자동 확장/축소, 보안의 기능을 가지고 있음 

> 기능 
	- High availability : 하나 이상의 AZ에 에 대해서 application 트래픽을 자동 분산함 
	- Health check : 리소스 대상에 대해서 비정상을 감지하고, 나머지 대상으로 트래픽을 분산함. 
	- Security : VPC를 사용하여 ELB와 연결된 security group 생성/관리하여 추가적인 보안 옵션 제공 
	- TLS (transport layer secure) : ELB에서 통합 인증서 관리 및 SSL/TLS 복호화를 지원함으로 로드 밸런서 SSL 설정을 중앙 관리하고 application CPU 집약적 작업을 줄여줌 
	-  L4, L7 로드밸런싱 
	- 어플리케이션 성능을 실시간으로 모니터링 할 수 있도록 CloudWatch 지표 및 request 트레이싱, 통합을 제공함 

> 질문 
	-  나의 application에 맞는 ELB 타입은 어떻게 결정합니까?	
		. HTTP 요청을 로드밸런싱 하는 경우 ALB 를 사용하는 것이 좋고, L3(network), L4(TCP,UDP) 로드밸런싱 필요한 경우와 높은 성응이 필요한 경우나 지연시간이 낮아야 하는 경우 NLB를 사용하는 것이 좋다. 만약 EC2-Classic 네트워크에 구축된 경우 CLB를 사용해야 한다. 
	- public IP를 사용하지 않고 VPC에서 ELB API에 비공개 액세스 할 수 있나?
		. VPC endpoint를 생성하면 VPC에서 ELB API에 비공개로 액세스 할 수 있음. VPC endpoint를 사용하면 IGW, NAT GW, VPN 연결 필요 없이 VPC와 API간 라우팅을 처리함. ELB이 사용하는 최신 VPC endpoint는 PrivateLink를 제공함. 이는 ENI를 사용하는 AWS 서비스와 VPC 내 privat IP 간 프라이빗 연결을 지원해주는 기술 
	- ELB에 대한 SLA가 제공되는가? 
		. 99.99% 가용성 보장
	- ALB 가 지원하는 OS는 무엇인가?  . 모든 운영체제에 대해서 지원함. 
	- ALB가 지원하는 프로토콜은 무엇인가? HTTP와 HTTPS 를 지원함 
	- ALB에서 HTTP/2가 지원되는가? 지원됨. HTTP/2를 지원하는 client는 TLS를 통해 ALB와 연결할 수 있음. 
	- ALB에서 TCP 포트를 사용해 로드밸런싱 가능한가? 1~65535 의 TCP 포트에 대해 로드 밸런싱 수행 가능 
	- ALB 웹소켓 지원되는가? 웹 소켓 및 보안 웹 소켓 지원이 기본적으로 제공됨 
	- ALB 에서 request tracing이 되는가? 기본적으로 활성화 되어 있음. 
	- CLB는 ALB와 동일한 기능 및 혜택을 제공하는가? 일부 중첩이 되는 기능이 있지만, 두 로드 밸런서 사이에 기능 패리티가 없다. ALB가 AWS application 레이어 로드 밸런싱 플랫폼을 담당한다. 
	- ALB 트래픽만 허용하도록 EC2를 구성 가능? 넹 
	- ALB 프론트 엔드에 보안 그룹 설정 가능? 넹 
	- CLB에 사용하는 기존 API를 ALB에 사용할 수 있음? 아니요 새로운 API 세트가 필요함 
	- ALB와 CLB를 동시에 관리하기 위해서는 어떻게 해야 하는가?
		. ELB 콘솔에서 ALB, CLB 모두를 관리할 수 있음. CLI / SDK 를 사용하는 경우 ALB 에 대해서는 다른 서비스를 이용해야 한다. 예를들어 CLI에서는 예를 들어 CLI에서는 Classic Load Balancer를 `aws elb describe-load-balancers`로 설명하고, Application Load Balancer는 `aws elbv2 describe-load-balancers`로 설명합니다.
	- CLB를 ALB로 전환하거나 그 반대로 전환 가능합니까? 아니요, 전환할 수 없지만, CLB를 ALB로 마이그레이션 가능합니다. 
	- ALB를 4계층 로드 밸런서로 사용할 수 있습니까?? 아니요. 그럴 경우 NLB를 써야 합니다. 
	- ALB를 사용해 HTTP 및 HTTPS 요청을 처리할 수 있습니까? 예. 80 포트, 443 포트 에 대한 리스너를 추가 가능합니다. 
	- 보안/운영 이슈 해결 목적으로 account 에서 이루어진 ALB 로드밸런싱 API 호출을 기록할 수 있습니까? 
		. 네. CloudTrail 을 사용하여 API 호출 기록을 얻을 수 있습니다. 
	- ALB는 HTTPS 종료를 지원합니까? 
		. 네. HTTPS 연결을 종료할 수 있습니다. SSL 인증서를 설치해야 합니다. 인증서를 사용하여 HTTPS 를 종료한 후 클라이언트 요청을 복호화 하여 대상으로 전송해야합니다. 
	- SSL 인증서를 받으려면 어떻게 해야 합니까? 
		. AWS Certificate Manager를 사용하여 SSL/TLS 인증서를 프로비저닝 할 수 있습니다. 또는 인증서를 요청하고 
		요청한 인증서에 CA 서명을 받은 후, AWS Certification Manager 또는 AWS IAM 서비스를 사용하여 인증서를 업로드해 다른 곳에서 인증서를 확보할 수도 있습니다. 
	- ALB에서 백엔드 서버 인증이 지원됩니까? 아니요 ALB를 사용하는 백엔드에 대해서는 암호화만 지원됩니다. 
	- VPC와 온프레미스 위치에 배포된 애플리케이션을 로드 밸런싱 하려면 어떻게 해야 합니까? 
		. APP이 vpc와 온프렘에 분포되어 실행된다면, 대상 IP주소를 사용해 대상을 같은 target group 으로 추가할 수 있음. 
		APP 에 영향 없이 AWS 마이그레이션 하기 위해 점진적으로 VPC 대상을 target group 에 추가하고 온프렘 서버를 제거함. 
		. 또는 VPC와 온프렘을 별도의 ELB로 구성한 뒤 Route53에서 DNS 가중치를 사용하여 로드 밸런싱 할 수 있습니다. 
	- NLB 리스너에 대해 4계층을 생성할 수 있습니까? 네, TCP/UDP , TLS  리스너 모두를 지원함 
	- NLB 주요 기능은 무엇입니까? 
		. NLB는 초당 수백만개 요청과 변동성이 높은 갑작스러운 트래픽 패턴을 처리하도록 설계하였으며, 지연시간이 매우 짧습니다. NLB는 TLS 종료를 지원하고 클라이언트 소스 IP를 유지하여 안정적인 IP지원 영역 격리 기능을 제공합니다. websocket 유형의 어플리케이션에 매우 유용한 장기간 연결도 지원합니다. 
	- CLB의 TCP 리스너와 비교하여 NLB는 어떻게 다릅니까? 
		. NLB는 CLB에서 유지하지 않는 client 소스 IP를 유지합니다. 고객은 CLB에서 proxy protocol을 이용해 source IP를 얻을 수 없습니다. NLB는 AZ 별로 고정 IP를 자동으로 제공하며, 로드 밸런서에서 AZ 당 EIP도 할당할 수 있지만, CLB는 제공하지 않습니다.
	-CLB에서 NLB로 마이그레이션 가능합니까? 네. 
	- ELB-제공 IP와 탄력적 IP가 혼합되었거나 프라이빗 IP가 할당된 Network Load Balancer를 사용할 수 있습니까?	
		. 아니요. Network Load Balancer의 주소는 사용자 또는 ELB가 완벽하게 제어해야 합니다. 이렇게 해야만 Network Load Balancer에서 탄력적 IP를 사용할 때 클라이언트가 알고 있는 모든 주소가 변경되지 않습니다.
	- CLB가 지원하는 프로토콜은 무엇입니까? HTTP, HTTPS, SSL, TPC 
	- CLB에 보안그룹을 설정 할 수 있나? 예. vpc를 사용하는 경우 CLB에 보안그룹 구성 가능 
	
	
3. CloudFront
- CDN, content delivery network 서비스로 보안적으로 데이터, 비디오, 어플리케이션 API들을 낮은 latency로 글로벌 고객에게 제공한다. CloudFront는 AWS에 통합되어 있는데, 물리적인 위치와 그것의 서비스들이 직접적으로 연결하였다. 
CloudFront는 AWS Shield를 통해서 DDoS, Distribute Denial of Service attack 등에 대한 균일하게 동작한다.   

> 기능 
	- 글로벌 엣지 네트워크 제공 200개의 PoP(189개의 edge location, 11개의 edge cache) 
	- 보안 
		. network/application layer 보호 : GW 역할소 사용함으로써 컨텐츠, 데이터, 코드 및 인프라에 대한 주요 공격을 차단
		. SSL/TLS 암호화 및 HTTPS 활성화 가능 : ACM을 사용해 SSL 인증서를 쉽게 생성하고 CloudFront에 무료 배포가능. 
		. 액세스 제어 가능 : 서명된 URL과 서명된 쿠키를 사용해 토큰 인증을 지원하여 인증된 최종 사용자만 액세스
		. 인터넷 규정 준수 : 표준을 준수 
	- 가용성 
		. 앱 가용성 향상 : CloudFront의 엣지 로케이션에 콘텐츠를 캐싱해 워크로드 줄일 수 있음
		. 여러 오리진을 설정하여 백엔드 아키텍처에 중복성 활성화 허용. 백업 오리진에서 콘텐츠 자동 제공 가능. 
	- 성능 
		. 네트워크 최적화 : AWS 글로벌 백본에서 실행되고, 여러 리전 및 앱에 걸쳐 edge 와 기타 AWS 간 요청 최적화
		. 동적 및 정적 컨텐츠 : ??? 
		. 대규모 라이브러리와 미디어 애셋 : CDN이 객체를 더 오래 유지하고 캐시 회전을 줄이도록 설계
	- 프로그래밍을 통한 배포, DevOps 지원 
		. API와 DevOps 제공 
		. 엣지의 다양한 동작방식 제공 
		. lambda@edge 를 사용해 코드를 사용자 더 가까운 위치에서 수행하는 것이 가능
	- 비용 효율적 
		. 사용한 만큼만 지불하는 일반요금과, 약정 트래픽 개별요금 제공 
		. AWS 클라우드와 CloudFront 간의 무료 데이터 전송 
> 시작하기 
	- 컨텐츠를 빠르게 전달하기
		. S3 버켓에 static content를 업로드하여, 그 S3 버켓을 CloudFront origin으로 사용할 수 있다. S3는 image, videos, HTML 페이지, .css 파일 .js 파일 등을 포함하여 CloudFront origin으로 사용하기 좋다.
		. 우선 S3에 static content를 read/write 권한으로 주고, public access 를 허용시킨다. 
		. 그 다음 CloudFront에서 'create distribution'을 수행한다. distribution의 설정에서 사용자가 요청할 때어떠한 origin에서 content를 가져올 것인지 설정하게 된다.  이번에 web-distribution은 S3(static)과 httpserver(dynamic)을 선택하면 된다. 
			1) 우선 컨텐츠 전달 방법을 설정한다. 'web distribution'은 static+dynamic content 위해 사용되고, 'RTMP distribution'은 어도비 플래쉬 미디어 서버의 RTMP 프로토콜을 사용하여 최적의 streaming media file을 위해 사용된다. 	여기서는 web-service를 수행할 것임으로 'web distribution'을 선택한다. 
			2) Origin Domain Name에 static content를 저장한 S3 버켓 이름을 입력하고, 나머지 설정은 default로 두고 distribution을 생성한다. 
			3) distribution 배포가 끝난 뒤 cloud front 도메인 명을 확인하고, 이미지 경로에 CloudFront의 distribution에 할당된 domain 이름을 입력한다. 그리고 object name에 S3버켓에 저장한 이미지 파일 이름을 입력한다. 
			4) 웹 페이지를 열면 해당 경로에서 파일을 가져오는 것을 확인할 수 있다.
			5) distribution의 사용이 종료되면 쉽게 disable 시킬 수 있고 과금되지 않는다. 그 후 해당 distribution을 사용하는 웹페이지들은 모두 사용이 불가능해진다. 

4. CloudTrail 
> 개요 
	- AWS account에 대한 governance, compliance, operational audit, risk audit 을 제공하기 위한 서비스. 
	- AWS infra 레벨에서 account 활동과 관련된 작업을 기록하고 지속적으로 모니터링 하며 보관할 수 있음. 
	- 관리 콘솔, SDK, CLI 등을 통해 작업을 수행하거나 정볼르 가져올 수 있으며, 이를 통해 보안 분석, 리소스 변경 추적, 트러블 슈팅을 빠르게 할 수 있음. 
> 기능
	- Always on : 계정 활동에 대해서 항상 on 상태로 수행되며 최근 90일의 account 활동들(서비스에 대한 생성, 수정, 삭제 명령)을 수동적인 CloudTrail 설정 없이도 사용할 수 있다. 
	- Event history : AWS account의 활동에 대해 조회, 검색, 다운로드 할 수 있고 account 리소스 변화를 시각화 함으로써 보안 분석이나 운영 이슈 해결을 단순화 시킨다. 
	- Multi-region configuration : 하나의 계정에 대해 여러 리전에 대한 CloudTrail 로그를 하나의 S3 버켓에 전달하도록 설정할 수 있는데, 이것은 기존에 존재하는 리전 뿐만 아니라 새로 런치되는 리전에도 적용된다. 
	- Log file integrity validation : S3에 저장된 /CloudTrail 로그 파일에 대한 무결성을 검증할 수 있으며, CloudTrail 이 S3에 기록한 뒤로 로그파일이 변경되었는지, 수정되었는지 삭제되었는지 확인 가능하다. 
	- Log file encryption : 기본적으로 CloudTrail은 S3 버켓의 모든 로그파일에 대해서 S3 server-side encryption(SSE)를 적용한다. 필요에 따라서 AWS Key Management Service를 이용해 보안 단계를 추가할 수 있다. 로그를 조회하는 사용자는 decryption 권한이 있다면 자동적으로 복호화하여 데이터를 조회하게 된다. 	
	- Data events : data event는 리소스에 대해 수행되는 명령에 대해 통찰을 준다. data event 높은 볼륨 활동들에 대해 수행되고, S3 object level API들이나 API로 인한 Lambda 함수 수행과 같은 API 연산 등에 대한 로그를 남긴다. (람다 수행, IAM 사용자/서비스 API 호출 등)
	- Management events : 관리측면에서 수행되는 활동(EC2 인스턴스 생성, 삭제 수정 등)이나 IAM 권한 추가, IP 주소 할당 등 에 대한 이벤트도 로그로 남긴다. 
	- 통합 
		. lambda와 통합되어 S3에 로그를 쓰면 S3는 람다를 호출하여 로깅된 정보에 대한 처리를 수행할 수 있다. 
		. CloudWatch가 CloudWatch와 CloudTrail에서 기록되는 로그에 대한 관리를 할 수 있게 한다. 메트릭을 생성하여 이벤트를 모니터링하고, 검색하고 AES 나 lambda로 로그를 스트리밍 할 수 있다. 
		. CloudWatch Event와 통합함으로써 자동적으로 AWS 리소스 변화에 대한 반응을 할 수 있다. 이를 통해 CloudTrail 특정 로그에 대해서 액션을 정의할 수 있다. CloudTrail이 EC2에 대한 security group 변경을 확인하면, CloudWatch가 lambda 함수를 수행할 수 있다. 
> 질문 
	- CloudTrail이란 무엇인가? AWS CloudTrail은 사용자 계정에서 이루어진 활동을 기록하고, 로그 파일을 사용자의 Amazon S3 버킷으로 전달하는 웹 서비스
	- CloudTrail의 이점은 무엇인가? CloudTrail은 사용자 계정에서 이루어진 작업을 기록함으로써 사용자 활동에 대한 가시성을 제공합니다. CloudTrail은 요청한 사람, 사용된 서비스, 수행된 작업, 작업의 파라미터, AWS 서비스에서 반환한 대응 요소를 비롯하여, 각 작업에 대한 중요 정보를 기록합니다. 이러한 정보는 AWS 리소스에 이루어진 변경 사항을 추적하고 운영 관련 문제를 해결하는 데 도움
	
5. CloudWatch 
> 기능 
	- 로그 수집
		. appliation / service 로그를 실시간으로 수집하고 저장. 로그 종류는 3가지로 나뉨 
			1) vended log -  AWS 기본적으로 제공하는 로그 (VPC flow log, Route53 log)  
			2) 각 AWS 서비스 게시 로그 - API GW, lambda, CloudTrail 등의 서비스에서 CloudWatch로 보내주는 로그   
			3) 사용자 지정 로그 - AWS system manager를 사용해 CloudWatch agent를 설치하거나 PutLogDataAPI로 로그를 CloudWatch로 보내줄 수 있음
		. 내장된 metrics 지원 : AWS 서비스들에 대해서 기본 metrics을 제공함 
		. 사용자 metrics 지원 : 사용자 지정 지표를 수집하여 metrics에 표시할 수 있음
		. 컨테이너 지표 및 로그 수집, 집계 : Container Insights를 활용해 컨테이너 에코 시스템 로그를 수집하고 집계가능. 
	- 모니터링 
		. 대시보드를 통한 통합된 운영 뷰 
		. 지표에 대한 임계값 설정으로 작업을 트리거링 함 
		. 로그와 지표를 연관시켜 알람을 설정할 수 있음 
		. 컨테이너 모니터링, 이상 탐지, 닷넷 및 SQLServer 어플리케이션 인사이트 
	- 조치 
		. Auto Scaling : 주요 지표에 대한 경보를 받고 자동화된 Auto Scaling 작업을 트리거 하도록 임계값 설정 가능 
		. CloudWatch Events 를 통한 운영 변경 자동화 : AWS 리소스에 대한 변경사항을 신속하게 대응하고 조치할 수 있음 
		. EKS, ECS 및 k8s 클러스터에서 알람 제공 및 작업 자동화 : EKS와 k8s의 경우 EC2 auto scaling 그룹에 대한 정책을 트리거하고 인스턴스관리할 수 있음 / ECS는 컴퓨팅지표를 auto scaling에 사용할 수 있음 
	- 분석 
		. 세분화된 데이터 및 확장 보존기간 
		. 지표에 대한 사용자 지정 작업 수행 
		. 로그 분석 
		. 지표, 로그 및 트레이스 분석 
	- 규정 준수 및 보안 
		. IAM과 통합되어 데이터에 대한 액세스 권한이 있는 사용자 및 리소스 액세스 방법 제어 
> 질문 
	- Amazon CloudWatch란 무엇인가?
		. AWS 리소스와 AWS에서 실행되는 application을 모니터링하기 위한 서비스 
		. 지표 및 로그 수집을 통해 모니터링하고 알람을 설정할 수 있음 
		. AWS 리소스 뿐만아니라 사용자 application에 대한 지표 및 로그도 모니터링 할 수 있음 
	- CloudWatch에 어떻게 액세스 할 수 있음? 
		. API, CLI, SDK 및 관리 콘솔을 통해서 접근 가능 
	- CloudWatch에서 지원하는 운영체제는?
		. 기본적으로 모든 EC2 인스턴스에 대한 지표 수신이 가능함으로 EC2에서 서비스하는 운영체제 
	- CloudWatch 액세스 관리 정책은?
		. IAM과 통합되어 특정 metrics에 대한 사용은 제한은 할 수 있음. 하지만 데이터에 대한 액세스 제어는 IAM을 통해서 사용할 수 없음 
		특정 인스턴스 그룹, 특정 ELB에 대해서만 권한을 부여할 수는 없음. 전체 클라우드 리소스에 대한 권한이 해당됨. 
		. 또한 CLI 수행도 IAM의 제어를 받지 않음 
	- CloudWatch Logs 는 무엇인가? 
		. 기존 시스템, application, 사용자 정의 로그파일을 이용하여 모니터링 할 수 있음 
		. 실시간 application 및 시스템 모니터링 가능 : 특정 구문, 값, 패턴에 대한 로그를 실시간 모니터링 할 수 있음.  
		. 로그 장기 보존 가능 : 내구성이 뛰어나고 비용 효율적인 스토리지에 무기한 로그 저장할 수 있음. 
		. 주요 OS들에 대해서 모두 지원하며, IAM과 통합하여 액세스 키, IAM 롤에 대한 접근 제어를 지원함 
	- CloudWatch Logs Insights 란 무엇인가? 
		. CloudWatch Logs를 위한 통합된 인터랙티브 로그 분석 기능으로 로그를 검색하고 시각화 하여 어플리케이션을 이해하고 디버그 할 수 있음. 
		. Logs Insight 는 바로 시작할 수 있으며 이를 통해 CloudWatch Logs의 모든 로그에 대한 쿼리를 실행할 수 있음 
	- CloudWatch Container Insights 란 무엇인가?
		. 컨테이너 application 및 마이크로 서비스에 대한 모니터링 및 알람, 문제 해결을 제공하는 기능 
	- CloudWatch Anomaly Detection 이란 무엇인가?
		. ML을 통하여 지속적으로 시스템과 어플리케이션에 대한 time series에 대한 지속적인 분석을 통하여 정상 상황을 정의하고 최소한의 사용자 개입을 통해 비정상 상황을 드러낸다. 
		. 자동으로 정의된 임계값에 대해서 알람을 생성할 수 있다. 그리고 anomaly detection을 통한 지표 시각화도 가능하다. 
		. CloudWatch 콘솔에서 Alarms 패널에 가서 알람을 생성하거나, Metrics에서 지표의 예상 값을 입력할 수 있다. 

6. Amazon Identity and Access Management (IAM) 
> 개요 
	- IAM은 AWS 서비스와 리소스에 대한 접근을 관리하여 보안을 강화하기위한 서비스이다. 
	- AWS 사용자와 그룹을 생성하고 권한적용을 통해 AWS 리소스에 대한 접근을 허용/거부 할 수 있다. 
	- IAM은 AWS account에 대한 추가적인 비용이 없으며, 사용하는 AWS 서비스에 대해서만 비용이 부과되어진다. 
> 기능 
	- 보안성 강화 / 세밀한 컨트롤 /임시적인 인증(roles) / 유연한 보안 인증 관리(pw, key-pair, X.509 cert, MFA) / 외부 인증 시스템 강화 (AD, Web Identity Provider 제공) / AWS 서비스와의 쉬운 통함 / 의도된 사용과 제한  
> 질문 
	- IAM 이란 무엇인가? 
		. Identity and Access Maangement로 개별 사용자 및 그룹에 대한 AWS resource 접근을 보안적으로 제어하기 위한 서비스이다. 
		. Identity(IAM user)를 생성하고 권한을 부여함으로써 resource에 대한 접근제어를 할 수 있다. 
		. 추가적으로 AWS 밖의 사용자(federated users-OSS)에 대한 권한도 부여 가능하다. 
	- 어떻게 IAM을 시작할 수 있는가? 
		. IAM을 시작하기 위해서는 적어도 하나의 IAM과 통합된 AWS service가 존재해야 한다. 
		. 그 뒤에 사용자, 그룹, 권한을 IAM API, CLI, IAM 콘솔을 통해서 생성하고 관리할 수 있다. 
	- IAM으로 해결되는 문제는 무엇인가? 
		. IAM user와 그들의 접근을 관리 제어 : 사용자 개별적으로 인증서(access key, password, MFA 장비) 또는 임시적인 보안 인증서를 요청하여 AWS 서비스와 리소스에 접근 가능하다. 사용자가 수행할 수 있는 기능을 명시할 수 있다. 
		. 연합 사용자(타 계정의)에 대한 관리 제어 : 유효기한 설정과 함께 보안 인증서를 요청하여 사용자들이나 application이 AWS account안에 있는 리소스에 대해 보안적 접근을 가능하도록 한다. 
	- 누가 IAM 을 사용할 수 있는가? 
		. AWS 고객에 대해서 추가적인 비용없이 서비스가 제공됨. 비용은 AWS 서비스를 사용할 때만 부과됨 
	- user의 정의는 무엇인가?
		. AWS 서비스와 어플리케이션에서 인지하는 유일한 identity로 OS의 사용자와 유사한 개념이다. pw와 access key와 같은 보안 증명을 통해서 인증할 수 있으며 unique name을 갖는다. 
		. user는 AWS 서비스에 접근하는 개인, 시스템, application일 수도 있다. IAM 은 이러한 user들을 IAM users 라고 칭하면서 IAM 에서 관리한다.
		. 또한 AWS 외부에서 관리되는 사용자 에 대하여 AWS resource에 대한 접근 권한을 부여할 수 있는데, 이러한 AWS 외부 사용자를 ferderated users 라고 한다. 

7. S3 
> 개요 
	- 비계층적 플랫구조로 데이터는 'bucket'이라는 리소스에 object로 저장되며, object 하나의 크기는 최대 5TB까지 가능. 
	- prefix 라고 하는 공유이름을 사용하여 구성할 수 있음. 
	- S3 object tag 라고 하는 key-value 쌍은 최대 10개까지 객체에 추가할 수 있고, 이러한 pair를 통해 객체 수명주기 동안 생성/업데이트/삭제 할 수 있음. 
	- S3 inventory 를 통해서 S3 버켓에 저장된 object 또는 특정 prefix 를 가지고 있는 object에 대한 레포트와 그 object의 메타데이터, 암호화 상태 등을 확인할 수 있음. 매일/매주 생성하도록 설정할 수 있음. 
> 기능 
	- 스토리지 관리 기능 
		. S3 bucket 이름, prefix, object tag 그리고 S3 inventory를 통해 데이터에 대해 그룹화 하고 레포트 할 수 있으며 다른 S3 동작에 대한 설정을 할 수 있다. 
		. S3 batch operation을 통해 수천개의 object를 저장할 수 있고, S3에 어떠한 규모로도 저장할 수 있도록 해준다.  
		  batch operation을 통해 버켓간 이동, object tag 설정 변경, 접근 제어 수정, S3 Glacier로 부터 아카이브된 오브젝트 복구 등을 수행할 수 있다.  이때 S3 API, S3 관리 콘솔이 사용된다. 
		  batch operation은 AWS lambda 함수를 사용해 object를 통한 비즈니스 로직 처리를 수행할 수 있게 한다. 
		  batch operation 이 수행 완료된다면, 알람을 받거나 변화에 대한 레포트를 받을 수 있다. 
		. S3는 데이터에 대한 버전 관리, 의도치 않은 삭제 방지, 여러 region 간의 데이터 복제를 통해서 데이터를 유지시켜준다.  
		S3 Versinoing 은 쉽게 이전 버전의 object로 복구 할 수 있도록 해준다. Multi-Factor Authentication(MFA) delete 를 설정하여 의도치 않은 삭제를 막을 수도 있다. MFA 가 활성화된 버켓의 객체를 삭제할 때는 AWS account 인증과 승인된 인증 장비에 보여지는 문자열을 입력해야 한다. S3 Cross Region Replication(CRR) 을 통해서 오브젝트(그것들의 메타데이터와 오브젝트 태그를 포함)를 여러 리젼에 복제하게 된다. 
		. 또한 S3 Object Lock을 통해서 WORM, write-once-read-many를 강제 할 수도 있다. 이 기능을 통해 retention 정책에 반하여 object version delete 을 방지할 수 있다. 이것은 complication 규제를 지키기 위한 방법으로도 사용된다. 이러한 object lock은 다른 sotrage class로 변경이되어도 적용이 된다. object lock은 2가지 방법에 의해서 설정되는데 governance mode 로 배포될 때 IAM 권한이 있는 AWS 계정은 S3 object lock을 삭제할 수 있따. 만약 더 강한 규제가 필요하다면, Compliance Mode를 사용할 수 있따. 이것을 통해서 root account 를 포함한 어떠한 계정도 삭제하지 못하도록 설정할 수 있다. 
	- 스토리지 모니터링 
		. AWS Cost Allocation Report 를 통해서 버켓 태그를 통한 사용량과 비용 집계를 할 수 있다. 버켓 태그는 여러 비즈니스 들에 대해 비용을 확인하기 위해서 적용하는 것이다. 
		. Amazon CloudWath를 이용해서 AWS resource 상태나 billing 경고를 보낼 수 있다. 
		. S3 Event Notification을 설정하여 workflow, alert, lambda 함수를 트리거 할 수 있다. 특정 S3 리소스에 대한 변경 작업이 발생하였을 때마다. 
	- 스토리지 클래스 
		. 서로다른 6개의 storage class를 제공함으로써 다른 비용과 데이터 접근 방식을 제공해준다. 
		. S3 Storage Class Analysis 를 통해서 접근 패턴을 모니터링 하고 더 낮은 비용의 클래스로 옮겨야 하는 객체들을 확인해준다. 
		. S3 Lifecycle을 설정하여 데이터 전송을 할 수 있으며, 객체에 대한 만료 기한을 정할 수도 있다. 
	- 접근 관리 및 보안 
		. S3기본적으로 S3리소스를 생성한 사람만 접근할 수 있도록 설정되어 있다. 다른 사용자를 위해서 여러 접근 관리 기능을 제공하고 있다. 
		. IAM을 통해서 사용자를 생성하고 그들만의 접근 권한을 설정하거나, Access Control Lists(ACLs)을 각 오브젝트 별 권한 있는 사용자에게 접근할 수 있도록 설정하거나, bucket policies를 통해 하나의 S3 버켓에 대한 권한을 설정할 수도 있다. 
		Query String Authentiatoin을 통해서 시간 제한이 있는 임시 URLs을 제공할 수도 있다. 
		. S3는 Audit log를 지원함으로써 누가 어떤 객체에 접근했는지와 같은 S3 리소스에 대한 완벽한 가시성을 제공해준다. 
		. VPC에서 S3 resource와 접근하기 위한 VPC endpoint를 사용한다. 
		. S3는 서버 사이드, 클라이언트 사이드 압호화를 제공한다. S3 Inventory 는 S3 오브젝트들에 대한 암호화 상태를 보여준다. 
		. S3 Block pulbic Access는 보안 제어의 집합으로 S3 bucket과 객체에 대한 public 접근 제어 를 막아준다. S3 관리 콘솔에서 모든 버켓/일부 버켓에 대해서 적용할 수 있다. 
		. Amazone Macie 는 S3의 데이터의 민감 정보를 발견하고 분류하고 보호해준다. 이것은 ML 기능을 사용해서 민감 정보를 인지하고 대쉬보드를 제공하여 시각화 해준다. 그리고 비정상 적인 접근에 대한 모니터링과 권한이 없는 접근과 의도치않은 데이터 누수에 대한 알람도 울려준다. 
	- Query in place 
		. S3 Select은 S3 자체의 기능으로 쿼리 성능을 400 까지 지원해주고 쿼리 비용으 80 % 감소시켜준다. 이것은 전체 오브젝트를 가져가는 것 대신 object 데이터의 서브셋을 가져가도록 지원해준다. 
		. Amazon Athena : S3 데이터에 대해서 별도의 데이터 추출과 적재 없이 쿼리할 수 있게 해준다. 이것은 standard SQL 구문을 사용하여 데이터를 분석하고 결과를 몇초안에 보여준다. (인터렉티브)
		. Amazon Redshift Spectrum : S3 에 대한 SQL을 직접적으로 수행시켜주는데 더 복잡하고 큰 데이터에 대한 쿼리를 수행한다. (대용량) 
		. Athena와 Redshift 모두 common data catalog와 데이터 포맷을 공유함으로 S3 에 대해서 둘 모두 사용가능하다. 
	- 대규모 데이터에 대한 전송 
		. S3 Trasfer Acceleration은 멀리 떨어진 S3 버켓간 데이터 전송을 최대 속도로 하기 위해 고안되었다. 
		. 더 큰 규모의 데이터에 대해서는 Snowball, Snowball Edge, Snowmobile을 통해서 물리적으로 이동시켜준다. 
		. AWS Storage Gateway를 통해서 on-premise application을 유지하면서 cloud storage를 사용할 수 있다. (on-prem 환경에서 S3 사용) 
		. AWS DataSync를 통해서 on-prem 데이터와 AWS 간의 데이터 동기화를 시켜줄 수 있다. 데이터 전송은 최대 10초 걸린다. 
		. AWs Transfer to SFTP 는 완전 관리형 서비스로 직접 S3에 업로드/다운로드할 수 있도록 한다. 
		
> 스토리지 클래스 
	- 범용적인 사용 
		.  S3 standard : 범용 목적으로 사용 
	- 알수 없거나 변화하는 액세스 
		.  S3 Intelligent Tiering : 두 개의 계층에 객체를 저장하는데, 하나의 계층은 빈번한 액세스에 맞게 최적화 되며, 다른 하나는 저렴하고 빈번하지 않은 액세스 패턴에 최적화 됨. 30일 동안 접근되지 않은 객체는 cold-s3 쪽에, cold-s3 쪽에서 접근된 객체는 다시 hot-s3 계층으로 전달된다.
	- 빈번하지 않은 액세스 
		. S3 standard-IA : 빈번하지 않은 액세스 // 자주 액세스 되지 않지만, 필요할 때 빠르게 액세스 해야 하는 데이터. 장기 스토리지, 백업 및 DR용 데이터 스토어에 이상적.
		. S3 one zone-IA : 빈번하지 않은 액세스 + 단일 AZ : S3 standard-IA 보다 약 20%의 비용 절감. 가용성 및 복원력이 필요 없는 경우 적합. (데이터 보조 백업 복사본 등) 
	- 아카이브 
		. S3 Glacier : 아카이브 // 안전하고 내구력 있으며 저렴한 스토리지. Glacier 에 직접 객체를 업로드 하거나, 수명주기 정책을 사용해 S3 스토리지 클래스와 Glacier 간 데이터를 전송할 수 있음 
		. S3 Glacier Deep Archive : 아카이브 + 가장 저렴 // 1년에 한두번 정도 액세스 할 수 있는 데이터의 장기간 보관 및 디지털 보존을 지원. compliance 요건 충족을 위해 장기 데이터(~10년)을 보관해야 할 때 사용. 

> 질문 
	- S3란 무엇인가 
		. 웹 인터페이스를 통해 0바이트부터 5테라까지 데이터를 object 단위로 저장할 수 있는 오브젝트 스토리지.  simple storage service로 매우 높은 지속성, 고가용성, 무한대에 가까운 데이터 확장성을 매우 낮은 가격에 제공해준다. 
	-  S3로 무엇을 할 수 있나?
		. 웹 인터페이스를 통해 간단히 데이터를 저장하고 가져올 수 있다. 사용한 만큼만 지불하고 매우 확장성있다. 
	- S3를 어떻게 시작하는가? 
		. 고유한 이름으로 버켓을 만들면된다. 
	- S3로 on-prem 환경에서 하지 못하는 무엇을 할 수 있는가? 
		. 추가적인 선행 투자나 성능제약 없이 거대하게 확장할 수 있다. 높은 가용성, 접근성 보안성을 낮은 가격에 제공한다. 
	- S3에서는 어떠한 타입의 데이터를 저장하는가? 
		. 모든 타입에 대해서 저장할 수 있다. 
	- S3에서 얼마나 데이터를 저장할 수 있나? 
		. 총 공간은 무한대이다. 개별 S3 object에 대한 범위는 0바이트에서 5테라까지이다. 하나의 PUT 명령으로 처리될 수 있는 객체 수는 5기가 이다. 100 메가가 넘는 객체에 대해서는 multipart upload 기능을 고려해야 한다. 
	- S3가 제공하는 storage class는 무엇인가? (위 참고) 
	- S3에 있는 데이터로 아마존은 무엇을 하는가? 
		. 데이터를 저장하고 비용청구를 위해서만 사용하고 데이터 자체에 대한 접근을 하지 않는다. 법에서 요구하지 않는 이상 외부로 제공하지 않는다. 
	- 아마존의 자체 데이터도 S3에 저장하는가? 
		. 그러하다. 개발자들이 많은 프로젝트에서 S3를 사용한다. 
	- S3 데이터를 어떻게 관리하는가 
		.key 기반의 오브젝트 저장소로 데이터를 저장하면 unique한 object key를 할당해서 데이터 조회시 사용된다. 이러한 key 는 어떠한 string 값도 될 수 있으며,  그것은 계층적 구조를 모방한다. 대안으로 S3 object tagging을 통해 모든 S3 bucket 들/ prefix들에 대해서 관리할 수도 있다. 
	- S3와 어떻게 인터페이스 할 수 있는가? 
		. S3 는 간단하게 REST 형식으로 객체를 접근할 수 있다. 
	- S3의 신뢰성을 어떻게 높일 수 있는가? 
		. S3는 고가용성, 고 확장성, 빠르고 비싸지않은 데이터 스토리지 인프라로 글로벌 네트워크를 통해 제공한다. S3 standard storage class 는 99.99% 가용성을 제공하고, S3 standard IA 99.9 % one-zone IA 99.5% 보장한다. 
	- application의 트래픽이 갑자기 증가하면 S3는 어떻게 그것을 처리하는가? 
		. S3는 거대한 확장을 통해서 로드를 균등하게 분산할 수 있다 어떠한 application도 증가하는 트래픽에 따른 영향을 받지 않는다. (단, 비용적 제한이 걸려 있지 않을 때) 
	- S3 는 SLA를 제공하는가? 
		. S3 SLA를 제공한다. 
		
8. EBS(Elastic Block Store) 
> 개요 
	- EC2 인스턴스에 붙일 수 있는 확장 가능한 block storage
	- 특정 AZ 안에 위치하여 자동으로 복제되어 가용성을 보장해준다. 
	- 모든 EBS 볼륨 타입은 지속가능한 스냅샷을 제공하고 99.999% 의 가용성을 보장하도록 설계되었다. 
> 특징 
	- 다양한 EBS volumne type을 지원한다. 
		. SSD-io1 : IO 집중적인 NoSQL 이나 RDB의 사용을 위함 (64,000 iops)
		. SSD-gp2 : 부트 볼륨, 낮은 지연성으로 수행해야 하는 interacvie application (16,000 iops) 
		. HDD-st1 : 빅데이터 데이터, 데이터 웨어하우스, 로그 처리 등을 위함 (500 iops) 
		. throughputqhso iops 를 잘 고려하여 선정해야 할 것으로 보임 
	- Data lifecycle manager를 통해서 EBS 스냅샷을 생성
		. 스냅샷 생성을 통해 EBS 볼륨 백업을 자동화할 수 있으며, 별도의 스크립트 작성할 필요가 없다. 
		. 정기적으로 스냅샷을 정리해줌으로써 비용을 일정하게 유지할 수 있다. 
		. 간단하게 tag를 달고 lifecycle police를 생성하여 백업을 관리를 할 수 있다. 
		. CloudWatch Event로 정책을 보니터링하고 백업이 정상적으로 되었는지 확인할 수 있다. 
	- Elastic Volumes
		. 동적으로 용량을 증가시키거나, 성능을 튜닝하고 타입을 변경할 수 있다. 이때 다운타임이나 성능 이슈가 없다. 
		. AWS lambda와 Cloudwatch를 사용해 자동으로 application이 필요한 변화를 충족시킬 수 있다. 
		. application 이 요구하는 변화에 대해서 더 쉽게 적용하고 차후에 필요한 리소스에 대한 수정이 용이하다. 
	- EBS Snapshot 
		. EBS는 point-in-time 스냅샷을 S3에 저장해 준다. 초기 저장 뒤에 incremental snapshot을 저장하여, 변화된 블럭에 대한 최소 가격만을 부과할 수 있도록 한다.
		. snapshot을 삭제할 때는 다른 snapshot 에서 필요하지 않는 데이터들만 삭제가 가능하다. 
		. snapshot은 여러개의 새로운 볼륨에 대해서 저장하기 위해서 사용되기도하는데, 더 큰 volume으로 확장하거나 볼륨을 다른 AZ로 이동시킬때도 사용된다. 
		. snapshot은 다음과 같은 특징을 갖는다. 
			1) 즉시 EBS 볼륨 데이터에 접근할 수 있다. 
			2) EBS 볼륨을 사이즈 수정이 가능하다. 
			3) EBS snapshot 공유가 가능하다. 
			4) Amazon EBS 스냅샷을 regions 간 복사할 수 있다. 
	- EBS optimized instance 
		. EBS에 최적화된 EC2 인스턴스를 기동할 수 있는데, 이것은 EC2 인스턴스가 EBS 볼륨의 iops를 완전히 사용할 수 있도록 해준다. 
		. optimized instancㄷ는 EC2와 EBS 사이의 dedicate thorughput을 500에서 10000 Mbps 로 맞춰준다. 
		. EBS의 모든 타입에 대해서 지원하며, optimized instance를 설정해야 한다. (EC2)
	- EBS 가용성과 지속성 
		. EBS는 기본적으로 고가용성과 안정성을 갖도록 고안되었다. 만약 EBS 볼륨 데이터의 변경이 일어나느 경우 AZ에 있는 여러 서버에 복사되어 single component failure로 인한 손실을 막는다. 
		. EBS 볼륨의 AFR(annual failure rate)은 0.1%-0.2% 사이로 볼륨 크기와 성능에 따라서 다르다. 
		. EBS 는 snapshot 기능을 지원함으로 point-in-time 백업을 통한 안정성을 확보할 수 있다. 
	- EBS 보안 - 암호화 및 IAM 
		. EBS 데이터 볼륨, 부트 볼륨, 스냅샷에 대해서 암호화를 제공하고 빌드와 보안 키 관리 인프라를 제거하였다.
		. 저장된 데이터에 대해서 보안을 적용할 수 있으며 amazon managed key 또는 AWS Key Management service를 통해서(KMS) 생성 관리할 수 있다. 
		. 추가적으로 EC 와 EBS 데이터, 부트볼륨 사이에서 데이터를 옮기면서 암호화가 발생할 수도 있다. 
		. EBS 볼륨은 IAM과 통합되어 IAM 이 EBS 볼륨에대한 접근 제어를 할 수도 있다. 
> 질문 
	- EBS 볼륨과 스냅샷 ID 길이가 2018년도에 변경되었는가?
		변경됨.
	- EC2 instance를 terminate 시키면 어떻게 되는가? 
		. 인스턴스 상태와 상관없이 EBS 안의 데이터들은 유지가 된다. 반면에 logical instance store에 저장되는 데이터는 따라서 삭제가 됨으로 임시 데이터에 대한 저장을 위해 사용되어야 한다. 
		. 고가용성과 안정성을 위해서 EBS 볼륨을 S3로 백업하는 것을 권고한다. 만약 EBS를 root partition으로 사용한다면 인스턴스 termination 수행 시 EBS가 삭제되지 않도록 delete on termination flag를 NO로 설정해야 한다. 
	- EBS 볼륨으로부터 어떠한 성능을 기대할 수 있는가? 
		. EBS의 다양한 볼륨타입을 통해서 다른 성능 특성과 가격을 가지고 있어 application에 맞는 타입을 선택해야 한다. 
	- 어떠한 타입의 EBS 볼륨을 선택하면 되는가? 
		. 크게 SSD와 HDD로 구분할 수 있다. 
		. SSD(solid state drive)는 IOPS에 따라서 선택하며, HDD(hard disk driver)는 빅데이터나 콜드 HDD(sc1)에 사용한다. 
	- 기존에 있는 EBS 볼륨에 대한 성능, 용량, 타입을 어떻게 바꿀 수 있는가? 
		. EBS 는 Elastic Volume 특성으로 API 호출, CLI 수행, 관리 콘솔을 통해 쉽게 변경 가능하다. 
	- EBS standard volume이 아직 사용가능한가? 
		. EBS standard volume은 EBS Magnetic volume 으로 변경되었다. 기존 볼륨은 EBS standard와 EBS magnetic volume 의 기능의 차이는 없다. 
		. 이름은 General Purpose SSD(gp2) 볼륨타입과 추천하는 기본 볼륨 타입의 혼동을 막기 위해서 수행되었다. 
	- SSD(io1)은 모든 EC2 인스턴스 타입에 대해서 사용가능한가? 
		. 네 모든 타입에 대해서 사용가능하다. 만약 EBS 볼륨에서 제공하는 iops를 사용하기 위해서는 EC2 instance 타입을 EBS-optimized instance로 선택해야 한다. 
		

9. EC2
 


10. Athena 
> 개요 
	- S3있는 데이터를 interactive 하게 SQL 표준을 사용하여 분석하기 위한 서비스. 
	- Athena는 서버리스로 인프라에 대한 관리를 할 필요가 없다. 
	- SQL을 사용할 수 있는 사람에게 별도의 복잡한 ETL 작업 없이 큰 규모의 데이터에 대한 빠른 분석을 지원해주는 서비스이다. 
	- Athena는 기본적으로 AWSGlue Data catalog와 통합할 수 있어, 통합된 metadata 레파지토리를 다양한 서비스들에대해서 만들고 데이터 소스로부터 schema를 확인하고, 새롭게 생성되거나 수정된 테이블이나 파티션 정의, 스키마 버저닝 관리등을 수행한다. 
	- 또한 Glue의 fully-managed ETL 능력, 데이터를 변한하거나 columnar 포맷으로 최적화하거 가격,성능을 향상시킬 수도 있다. 

> 기능 
	- 서버리스 서비스 
	- 쉽게 시작할 수 있다: 빌트인된 쿼리 편집기로 바로 DDL 구문을 수행하거나 쿼리를 시행시킬 수 있다. 또한 glue를 통해서 데이터 소스를 크롤링해서 Data catalog 정보를 갱신하거나 생성할 수 있다. 
	- 표준 SQL로 쉽게 쿼리할 수 있다 : Presto 기반의 분산 sQL 쿼리 엔지을 사용하여 낮은 latency와 데이터에 대한 ad-hoc 분석을 지원한다. 그렇기 때문에 S3에 대해서 ANSI SQL 수행할 수 있다. 또한 Athena JDBC driver 를 사용해 다양한 bi 툴에서 접근할 수도 있다. 
	- 쿼리 당 가격을 지불할 수 있다 : 쿼리 수행시 스캔한 데이터의 양에 따라서 가격이 지불된다. 그렇기 때문에 압축, 파티셔닝, 칼럼 포맷으로의 변환을 통해서 가격을 절약할 수 있다. 
	- 빠른 성능을 보장한다 : athena는 자동으로 쿼리를 병렬처리하고 큰 규모의 데이터라고 할지라도 쿼리의 결과를 몇초내로 보여준다. 
	- 고가용성, 지속성을 보장한다. : 쿼리를 여러 컴퓨팅 리소스를 통해서 수행되기 때문에 특정 컴퓨팅 리소스가 사용 불가능 하더라도 처리 가능하다. athena는 s3를 사용하기 때문에 데이터에 대한 고가용성과 지속성을 보장한다. 
	- 보안성  : IAM 정책, ACL, S3 bucket 정책을 통해서 접근 제어를 할 수 있다. IAM을 통해서 S3 bucket에 대한 세밀한 제어를 할 수 있다. S3 제어를 함으로써 사용자에게 athena 쿼리 제한을 할 수 있다. 
	athena는 또한 쉽게 S3내의 암호화된 데이터에 대해서 쿼리할 수 있고 암호화된 데이터를 S3 버켓에 쓸 수 있다. 서버 단, 클라이언트 단 암호화되 지원한다. 
	- 통합성 : 쉽게 Glue와 통합되어 통합 메타데이터 레파지토리 생성하여 여러 서비스들에게 제공할 수 있고 데이터로부터 크롤링하여 데이터 카탈로그를 생성하거나 갱신할 수 있다. 
			또한 Glue를 통해 완전 관리형 ETL 능력을 제공하거나, columnar 포멧으로 변경하여 비용/성능 최적화를 할 수 있다. 
> 질문 
	- Athena 란 무엇인가? 
		. ANSI SQL 을 사용해 S3에 저장된 데이터를 분석하기 위한 interactive query 서비스. 
		. 서버리스 서비스로 관리부담이 없으며 빠르게 시작할 수 있다. 
		. presto 기반으로 병렬적으로 쿼리를 수행하며, 다양한 포맷에 대해 처리가 가능하다. 
		. glue와도 연계하여 데이터에 대한 메타데이터를 관리할 수 있으며, 쿼리 수행 전에 스키마를 정의하여 쿼리할 수도 있다. 
		. quicksight 와 통합하여 쉽게 시각화 할 수 있으며, big-big join, windows function 등을 사용해 복잡한 분석 가능하다. 
	- Athena로 무엇을 할 수 있는가? 
		. S3에 저장된 데이터를 별도로 집계하거나 로드할 필요 없이 ANSI SQL을 사용하여 처리가능하다. 
		. 다양한 포맷의 데이터를 처리 가능하며, quicksight와 통합되어 쉽게 시각화를 할 수 있다. 
		. 보고서를 작성하거나 ODBC/JDBC 드라이버를 사용하여 BI 툴이나 SQL 클라이언트로 데이터를 탐색할 수 있다. 
	- 어떻게 Athena를 시작할 수 있는가? 
		. 관리콘솔에서 ddl 을 작성하거나 위자드를 사용하여 스키마를 작성한 후 쿼리 편집기를 사용해 s3 데이터에 대해서 직접 쿼리함. 
	- 어떻게 Athena에 접근할 수 있는가? 
		. 관리콘솔, API, ODBC/JDBC 드라이버를 통해 액세스 가능 
	- Athena와 관련된 서비스 한도에는 어떤게 있는가? 
		. 한번에 20개의 ddl 쿼리, dml 쿼리를 수행할 수 없음. (같은 타입에 대해서) account에 따라 병렬 쿼리에 대한 제한이 있음. 
	- Athena의 기반 기술은 무엇인가? 
		. ANSI SQL 을 완벽하게 지원하는 presto를 사용하며 다양한 파일 포맷과 호환됨. DDL 엔진의 일부는 HiveSQL DDL을 사용함. 
	- Athena 테이블 정의와 스키마 저장은 어떻게 하는가? 
		. S3의 데이터에 대해 사용자가 생성한 DB, table 정보 및 스키마 저장을 위해서 관리형 데이터 카탈로그 서비스를 사용함 
		. glue가 제공되는 리전에서는 athena 에서 glue를 사용하도록 업그레이드 할 수 있음 
		. glue가 제공되지 않는 리전에서는 athena 내부 카탈로그를 사용함. 
		. DDL 또는 관리콘솔을 통해 카탈로그 수정을 할 수 있습니다.
		. athena는 'schema-on-read' 기술을 사용해 쿼리가 실행될 때 사용자 테이블 정의가 동적으로 S3 데이터에 적용되어 별도로 저장할 필요가 없다. 
	- Glue 데이터 카탈로그를 사용하도록 업그레이드 해야 하는 이유는 무엇인가? 
		. glue는 완전 관리형 ETL 서비스. 
		. 3가지의 주요 기능을 가지고 있음. 이를 활용하기 위해서 업그레이드 하면 좋음 
			1) 자동으로 데이터 원본을 스캔하고 데이터 형식을 파악해 스키마를 추론하는 크롤러 > 자동 스키마 및 파티션 인식  
			2) 데이터를 변환하고 다양한 대상으로 이동할 수 있는 완전 관리형 ETL 서비스 > 간편하게 파이프라인 구축 
			3) S3 또는 ODBC/JDBC 호환 데이터 스토어에 저장된 DB, table에 관한 메타 정보를 저장하는 데이터 카탈로그  > 통합 메타데이터 레파지토리 
	- Athena, EMR, Redshift 차이점은 무엇인가? 
		. Redshift는 엔터프라이즈 보고 및 BI워크로드에 대해 가장 빠른 쿼리 성능을 제공함. 
		. EMR은 하둡 에코로 구성된 분산 처리 프레임워크를 온프렘 보다 빠르게 배포하고 비용효율적으로 실행 가능. 
		. Athena는 서버리스로 S3 데이터에 대한 임의 쿼리를 가장 쉽게 실행할 수 있음. 
	- EMR, Redshift와 Athena는 각각 언제 사용해야 하나? 
		. Redshift는 다양한 소스 데이터를 하나의 공통 형식으로 취합하여 장기간 보관하고 과거 데이터에 대해 정교환 비즈니스 보고서를 작성할 필요가 있는 경우
			비정형 데이터가 아닌, 정형데이터에 대해 대규모 DB 테이블을 조인하는 경우에 최적의 성능을 내도록 되어 있음
		. Athena는 데이텨 형식 지정 또는 인프라 관리에 대해 고민할 필요 없이 S3에서 인터렉티브 쿼리를 쉽게 실행하여야 하는 경우. 
			예로, 성능 이슈를 해결하기 위해 특정 서버 웹로그에 대해서만 처리해야 하는 경우
			S3의 데이터를 Redshift에 로그하고 그것을 Athena에 등록하여 쿼리할 수도 있음. 
		. EMR은 SQL 외에도, ML, 그래프 분석, 데이터 변환, 스트리밍 데이터 코딩 등 범용적인 처리가 가능함. 
			사용자 코드를 사용하여 데이터를 처리해야 하는 경우에 적합 
			Athena 데이터 카탈로그는 hive metastore와 호환되고, EMR에 hive metastore 저장되어 있는 경우 Athena에서 DDL로 스키마 생성하여 바로 처리할 수 있음. (상당 부분 지원함) 

11. Kinesis 
> 개요
	- 실시간 데이터, 스트리밍 데이터에 대해서 수집, 처리, 분석할 수 있는 서비스. 확장성과 유연성을 통해 가격 효율적으로 기능들을 제공한다. 
	- 비디오, 오디오, 어플리케이션 로그, 웹사이트 클릭 스트리밍, IoT 데이터를 ML, 분석 등을 위해서 수집할 수 있다. 
	- 데이터가 수집됨과 동시에 데이터를 처리하고 분석할 수 있다.
> 종류 
	- Kinesis Data stream (KDS) = hbase-phoenix
		. 다양한 실시간/스트리밍 데이터에 대해서 수 많은 소스에서 초당 기가바이트 규모 데이터를 가져와 분석/처리하기 위한 서비스
		. Producer 를 통해서 data stream에 데이터를 넣어주고, 하나 이상의 consumer에 의하여 데이터가 사용됨. 
	- Kinesis Data firehose
		. Streaming data를 변환한 후 Datalake, Data store, 분석도구에 로드함으로써 실시간으로 분석할 수 있도록 도와주는 완전 관리형 서비스
		. Kinesis data delivery stream은 Data firehose의 기본 구성요소임. data delivery stream을 생성하고 producer가 delivery stream에 데이터를 넣어주면 Data firehose 를 사용하여 데이터를 변환하고 destination에 데이터를 전송한다.
	- Kinesis Data analytics
		. Streaming data를 분석하고 실행 가능한 통찰력을 확보해 비즈니스	
	- Kinesis Video Data stream
		. 다양한 디바이스에 대해 비디오, 오디오, 인코딩된 데이터를 수집, 처리 저장하는 서비스 
> 기능 
	- Data Firehose
		. 쉽게 시작하고 구성할 수 있다. 
		. 준실시간으로 새로운 데이터를 적재할 수 있다. 
		. 데이터 처리량의 변화를 처리하기 위해 elastic scaling을 수행한다. 
		. 빌트인 데이터 포맷으로 변환 지원 : parquet 이나 orc와 같은 칼럼 기반의 데이터 포맷으로 변환을 지원한다. 
		. 통합된 데이터 변환 : stream 데이터 를 저장소에 저장하기 전처리를 위해 빌트인 람다 blueprint를 제공하여 일반적인 데이터 소스의 데이터를 json이나 csv 와 같은 포멧으로 변경토록 제공한다. 
		. 다양한 데이터 destination을 제공한다 : S3, Redshift, AWS ES, Splunk 등 
		. 선택적으로 자동 암호화를 제공한다 
		. 성능 모니터링을 위한 지표를 제공한다 : CloudWatch 를 포함한 지표를 제공하며 모니터링 할 수 있게 한다. 
		. 변환된 데이터에 대한 것만 비용을 지불한다. 
	- Data Analytics 
		. 서버리스 서비스 
		. 탄력적인 요금 : streaming app을 수행하는데 사용된 리소스에 대한 비용만 내면 되며, 프로비저닝 되는 인프라에 대해서는 상관하지 않아도 된다. 
		. 1초 미만의 처리 지연 시간을 제공하여 빠른 대시보드 및 actionable insights 를 생성함 
		. SQL / JAVA 개발자들을 위한 편의성 제공 : 사전에 정의된 템플릿, 고급 처리 함수 지원 등 
> 질문 
	- Kinesis Data stream이란 무엇인가?
		. 다양한 실시간/스트리밍 데이터에 대해서 수 많은 소스에서 초당 기가바이트 규모 데이터를 가져와 분석/처리하기 위한 서비스이다. 
		. 분석/처리하기 위해 사용자 커스텀 어플리케이션을 사용할 수 있다. 
		. 십만개의 소스에서 click strema, application log, social media 같은 다양한 유형 데이터를 지속적으로 KDS 에 추가 가능
	- Kinesis Data stream에서 자동으로 관리되는 것은 무엇인가? 
		. 데이터 처리량 기반으로 필요한 스트리밍 데이터에 대한 인프라, 저장소, 네트워킹 설정을 관리함. 프로비저닝, 배포, HW,SW관리 등을 신경쓸 필요가 없음. 
		. 또한 KDS는 데이터를 3개의 AZ에 복제하여 데이터 지속성과 고가용성을 보장함. 
	- Kinesis Data stream를 어떻게 사용해야 하는가? 
		. 로그와 데이터에 대한 실시간 처리 / 실시간 메트릭, 리포팅 / 실시간 데이터 분석 / 복잡한 스트리밍 처리 등에 사용 할 수 있음. 
		. 관리 콘솔이나 CreateStream 연산을 통해 data stream 생성 - producer 설정하여 지속적으로 data stream 에 추가될 수 있도록 함 - Kinesis app을 통해서 data stream 에서 데이터를 읽고 처리할 수 있도록 함. 
	- Kinesis Data Stream와 Simpe Queue Service의 다른점은 무엇인가? 언제 KDS를 써야하고 언제 SQS를 써야 하는가?  
		. KDS : 대규모의 스트리밍 데이터의 실시간 처리를 위해서 레코드 정렬 및 다른 어플리케이션으로 전달 가능하다. KCL, Kinesis client Library를 통해 모든 레코드를 주어진 파티션 키로 같은 레코드를 가진 프로세서로 전달해 KDS의 데이터를 다양한 application에서 읽도록 하기 쉽다. 
			KDS 는 다음과 같은 경우에 권고된다. 
				1) 유관 레코드를 같은 레코드 프로세서로 전달하는 경우(streaming Mapred 같은). 집계 처리나 카운트 처리를 할 때 
				2) 레코드의 정렬을 해야 하는 경우. 앱 로그를 처리/아카이빙 호스트로 순서를 유지하면서 보내야 하는 경우 
				3) 여러 어플리케이션이 동시에 같은 스트림을 소비해야 하는 경우. 예로 하나의 앱은 대쉬보드에 뿌려주면서, 다른 앱은 레드쉬프트로 적재해야 하는 경우 
				4) 몇 시간 이내에 순차적으로 레코드를 소비해야 하는 경우. 최대 7일까지 데이터를 저장할 수 있음. 빌링 어플리케이션을 위한 audit을 위한 어플리케이션을 수행할 수 잇음. 
		. SQS : 신뢰성있고 고가용적인 host 기반의 큐 서비스로 컴퓨터 간 메세지를 저장하는데 사용한다. 이것은 분산 어플리케이션 컴포넌트간의 이동을 쉽게하며, 메세지를 어플리케이션과 독립적으로 빌드할 수 있도록 도와준다. 
				1) 메세지 레벨의 의미(메세지 레벨의 ack/fail)과 시각화 타임아웃. 어떠한 작업에 대한 성공/종료에 대한 메세지를 전달할 때, 어플리케이션은 지속되는 checkpoint나 cursor를 가질 필요가 없어진다. 
				2) 개별적 메세지의 지연. 작업 큐에서 개별 작업들이 딜레이되는 경우 이러한 메세지를 최대 15분까지 지연시킬 수 있다. 
				3) 동적으로 읽기에 대한 동시성/처리량을 늘리고 싶은 경우. 작업 대기열이 있으며 백로그가 지워질 때까지 더 많은 리더를 추가하려는 경우.
				4) SQS의 확장 투명성을 활용하는 경우. 순간적으로 메세지/트래픽 증가로 인한 버퍼가 필요한 경우
	- Kinesis Data firehose는 무엇인가?
		. 데이터 저장소나 분석 도구로 가장 쉽게 streaming data를 적재할 수 있는 서비스이다. 
		. streaming 데이터를 캡쳐해 변환하고 다시 S3, Redshift, ES 같은 곳에 적재하는데 준 실시간으로 분석할 수 있게 한다. 
		. 완전 관리형 서비스로 처리량에 따라서 자동으로 확장하고 관리할 필요가 없다. 
		. 배치 압축 암호화를 제공하여 데이터 량의 감소 및 보안성을 강화시킬 수 있다. 
	- KInesis Data Firehose 에서 자동으로 관리되는 것은 무엇인가?  
		. 데이터 캡처하여 변환 적재하는데 필요한 모든 인프라, 스토리지, 네트워킹 및 구성을 관리함. 
		. 사용자의 관리자 개입 없이 자동으로 확장되고 3개의 region에 데이터를 동기적으로 복제하여 데이터가 대상으로 전송될 때 고가용성, 안정성을 보장함. 
	- Kinesis Data Firehose를 사용하려면 어떻게 해야 하나?
		. Firehose 콘솔 > CreateDeliveryStream 수행 > Kinesis Data Firehose 전송 스트립 생성됨 > 전송 스트림에 AWS lambda 함수 구성하여 변환 작업 정의 
		> Kinesis agent 또는 firehose API로 데이터가 전송 스트림으로 지속적으로 전송 되도록 데이터 producer를 구성 > 데이터를 지정한 대상으로 계쏙해서 자동 로드 함 
	- Kinesis Data Analytics 란 무엇인가? 
		. 스트리밍 데이터를 분석하고 actionable insight 를 생성하기 위한 서비스 
		. 내장된 템플릿, 처리함수에 대한 연산자를 사용함으로써 규모에 관계없이 쉽게 분석할 수 있고, AWS 서비스와 빌드, 관리 및 통합의 복잡성을 줄여준다.
	- 실시간 streaming processing/analytics 가 무엇이고 왜 필요한가?
		. 데이터가 도달함과 동시에 이에 대한 가시성 확보로 실시간으로 비즈니스를 모니터링 하고 새 비즈니스 기회를 얻을 수 있음
		. 이를 수행하기 위해서는 실시간 데이터를 수집하고 분석할 수 있는 도구가 필요함. 
		. 실시간 데이터는 데이터가 수신되는 대로 처리되어야 하며, 시간당 수백만개의 이벤트를 처리해야 함. 
	- Kinesis Data Analytics로 할 수 있는 일은 무엇인가?
		. Streaming ETL : 소스 데이터 정리, 보안, 필터링 하여 배치 ETL 단계 절감/제거 
		. 지속적 지표 생성 : 시간에 따른 데이터 추세를 모니터링 할 수 있음. SQL / java 프로그램을 통해 시계열 분석을 지속적으로 생성 가능 
		. 반응형 실시간 분석 : 특정 지표가 정의된 임계값에 도달하는 경우 기계학습 알고리즘을 통해 알람 전송 
	- Kinesis Data Analytics를 사용하려면 어떻게 해야 하는가? 
		. java : 관리 콘솔에서 stream processing application 생성 또는 CLI 또는 SDK 를 사용하여 생성 > IDE에서 AWS 와 연결함 > open source java library(Apache Flink)를 통해 개발함 > 일단 개발되고 나면 처리량에 따라서 자동적으로 auto-scaling 될 수 있음 
		. sql : 관리 콘솔에서 stream processing application 생성 또는 CLI 또는 SDK 를 사용하여 생성 > 들어오는 데이터를 정의 > SQL 작성 > 결과를 저장할 곳을 정의 >SQL 템플릿을 통해서 자동적으로 확장 가능 
		
12. QuickSight 
> 개요 
	- 완전 관리형 서비스로 쉽게 interactive 대쉬보드를 제공해준다. 
	- 대쉬보드는 어떠한 장비에서든 접근될 수 있으며, 어플리케이션이나 포털, 웹사이트에서도 접근 가능하다. 
	- 세션 당 과금을 하여 그들이 필요한 데이터 만큼만을 과금하게된다. 
> 기능
	- ML 인사이트 제공 / 사용한 만큼만 비용 지불 / 수만 명의 사용자들을 위한 확장  가능 / 임베디드 분석 / end-to-end BI 솔루션 구축 / 모바일 지원  
> 질문 
	- QuickSight란 무엇인가?
		. 빠르고, 쉽게 클라우드 환경에서 시각화를 통해 비즈니스 분석을 돕는 서비스 
		. 다양한 데이터 포멧과 소스 시스템을 설정하여 대쉬보드를 구성할 수 있다. (S3, Athena, RDS, Redshift, Aurora 뿐만 아니라 On-premise DB까지 지원한다) 
		. 인메모리 엔진(SPICE)를 사용하여 수백만명의 사용자가 빠르고 바로 응답하는 쿼리 성능을 제공받을 수 있다. 
	- QuickSight가 기존의 BI 솔루션과 다른점은 무엇인가?
		. 전통적인 BI 툴은 레포트를 작성하기 전에 복잡한 데이터 모델을 구성하는데 오랜 시간이 걸렸고 data engineer 팀이 필요로 했다. 
		그리고 ad-hoc 데이터 탐색이나 시각화가 부족했으며 미리 정의된 쿼리나 레포트를 수행할 수 있는 사용자의 수가 제한이 있었다. 
		추가적으로 비싼 HW, SW가 선행투자 되었어야 했다. 이러한 복잡성과 비용은 비즈니스 분석에 대한 어려움이었다. 
		. Amazon Quick Sight는 클라우드 환경에서 확장성과 유연성 있는 비즈니스 분석을 제공함으로써 간단하고 빠른 성능을 제공한다. 
		데이터 소스로 부터 큰 어려움 없이 연결하여 데이터를 SPICE 최신으로 유지하게 된다. SPICE 는 데이터 탐색과 비즈니스 분석을 제공해 고객의 비즈니스 인사이트를 찾도록 해준다. 
		이때 별도의 프로비저닝이나 인프라 관리는 고려하지 않아도 된다. 또한 이는 많은 분석 기능을 모든 사용자들에게 비싼 선행 비용없이 제공해준다. 
	- SPICE 란 무엇인가?
		. Super-fast, Parallel, In-memory Calculation Engine 의 준말로 클라우 환경에서 이는 칼럼 스토리지와 인메모리 기술의 조합을 사용한다. 
		. 이것을 통해 빠른 성능과 인프라를 관리하지 않아도 된다. 데이터에 대한 SPICE 사용자에 의해서 명시적으로 지워지기 전까지 유지된다. 
		. SPICE 는 자동으로 데이터를 복제하여 고가용성을 제공하고 수백만 사용자를 위해 확장되며 동시에 다양한 AWS 데이터 소스로부터 빠른 interactive 분석을 제공해준다. 
	- 어떻게 QuickSight를 시작할 수 있는가? 
		. 사용자에게 1gb 의 SPICE 가용공간을 무료로 제공해준다. 

13. RDS

14. Aurora 
 

------------------------------------------------------------------
서비스 확인 
1) managed service 인가? 아닌가?
2) serverless service 인가? 아닌가?
3) VPC 내부 서비스인가? 아닌가?
